{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Improved_Torrent_To_GDrive_v5.0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Read First: Terms and Recommended Flow\n",
        "\n",
        "Only download content you have rights to. Respect Google Colab and Google Drive Terms of Service.\n",
        "\n",
        "For large or long transfers, prefer the Drive API uploader (see ‚ÄúExample 5‚Äù) over Drive mount writes. The notebook defaults to downloading locally and uploading via the API for better reliability.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üì• Torrent ‚Üí Google Drive Downloader (Enhanced v5.0)\n",
        "\n",
        "**Improvements in this version:**\n",
        "- ‚úÖ Proper session cleanup (prevents memory leaks)\n",
        "- ‚úÖ Resume capability for interrupted downloads\n",
        "- ‚úÖ Better error handling and recovery\n",
        "- ‚úÖ Enhanced progress tracking with ETA\n",
        "- ‚úÖ Keyboard interrupt handling with resume data saving\n",
        "- ‚úÖ Safer settings_pack fallback logic\n",
        "\n",
        "This notebook uses modern libtorrent 2.x API with robust error handling.\n",
        "\n",
        "‚ö†Ô∏è Only download content you are legally allowed to download.\n",
        "\n",
        "**Tips:**\n",
        "- If Drive mount fails, files save to `/content/torrents/`\n",
        "- Public trackers are injected by default for better peer discovery\n",
        "- Use `resume_file` parameter to continue interrupted downloads\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Mount Google Drive (optional, robust fallback)\n",
        "import os\n",
        "\n",
        "drive_mounted = False\n",
        "IN_COLAB = False\n",
        "try:\n",
        "    from google.colab import drive as _colab_drive\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    _colab_drive = None\n",
        "    IN_COLAB = False\n",
        "\n",
        "try:\n",
        "    if IN_COLAB:\n",
        "        if not os.path.exists('/content/drive/MyDrive'):\n",
        "            _colab_drive.mount('/content/drive', force_remount=True)\n",
        "        drive_mounted = os.path.exists('/content/drive/MyDrive')\n",
        "        if drive_mounted:\n",
        "            print('‚úÖ Google Drive mounted: /content/drive/MyDrive')\n",
        "except Exception as e:\n",
        "    print('‚ö†Ô∏è Google Drive mount failed:', e)\n",
        "    drive_mounted = False\n",
        "\n",
        "if not drive_mounted:\n",
        "    os.makedirs('/content/torrents', exist_ok=True)\n",
        "    print('Using local path: /content/torrents')\n",
        "else:\n",
        "    # create a default folder inside MyDrive for convenience\n",
        "    default_gdrive_path = '/content/drive/MyDrive/Torrent'\n",
        "    os.makedirs(default_gdrive_path, exist_ok=True)\n",
        "    print('Using Google Drive path:', default_gdrive_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install libtorrent (2.0.11) and requests if missing\n",
        "import sys\n",
        "import subprocess\n",
        "import importlib\n",
        "\n",
        "def pip_install(pkg):\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pkg])\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f'pip install failed for {pkg}:', e)\n",
        "        raise\n",
        "\n",
        "lt = None\n",
        "try:\n",
        "    import libtorrent as lt\n",
        "    print('‚úÖ libtorrent present:', getattr(lt, 'version', getattr(lt, '__version__', 'unknown')))\n",
        "except Exception:\n",
        "    print('‚ö†Ô∏è libtorrent not found. Trying libtorrent==2.0.11 ...')\n",
        "    try:\n",
        "        pip_install('libtorrent==2.0.11')\n",
        "        importlib.invalidate_caches()\n",
        "        import libtorrent as lt\n",
        "        print('‚úÖ libtorrent installed:', getattr(lt, 'version', getattr(lt, '__version__', 'unknown')))\n",
        "    except Exception as e:\n",
        "        print('Primary install failed, trying alternative wheel name py3-libtorrent...')\n",
        "        pip_install('py3-libtorrent')\n",
        "        importlib.invalidate_caches()\n",
        "        import libtorrent as lt\n",
        "        print('‚úÖ libtorrent installed via py3-libtorrent:', getattr(lt, 'version', getattr(lt, '__version__', 'unknown')))\n",
        "\n",
        "try:\n",
        "    import requests\n",
        "except Exception:\n",
        "    print('Installing requests...')\n",
        "    pip_install('requests')\n",
        "    importlib.invalidate_caches()\n",
        "    import requests\n",
        "    print('‚úÖ requests installed')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Enhanced torrent engine with proper cleanup and resume support\n",
        "import libtorrent as lt\n",
        "import time\n",
        "import os\n",
        "import urllib.parse\n",
        "import math\n",
        "import shutil\n",
        "import traceback\n",
        "\n",
        "def _create_session(settings: dict):\n",
        "    \"\"\"Try lt.session(settings) first; fallback to settings_pack + apply_settings.\n",
        "    Enhanced with safer attribute access.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        ses = lt.session(settings)\n",
        "        return ses\n",
        "    except TypeError:\n",
        "        # Fallback to settings_pack for older bindings\n",
        "        sp = lt.settings_pack()\n",
        "        for k, v in settings.items():\n",
        "            try:\n",
        "                # Try direct attribute access first\n",
        "                if hasattr(lt.settings_pack, k):\n",
        "                    key = getattr(lt.settings_pack, k)\n",
        "                # Try setting_by_name if available\n",
        "                elif hasattr(lt.settings_pack, 'setting_by_name'):\n",
        "                    key = lt.settings_pack.setting_by_name(k)\n",
        "                else:\n",
        "                    # Skip unknown settings\n",
        "                    continue\n",
        "                \n",
        "                # Set value based on type\n",
        "                if isinstance(v, bool):\n",
        "                    sp.set_bool(key, v)\n",
        "                elif isinstance(v, int):\n",
        "                    sp.set_int(key, v)\n",
        "                else:\n",
        "                    sp.set_str(key, str(v))\n",
        "            except (AttributeError, TypeError, ValueError) as e:\n",
        "                # Silently skip invalid settings\n",
        "                pass\n",
        "        \n",
        "        ses = lt.session()\n",
        "        ses.apply_settings(sp)\n",
        "        return ses\n",
        "\n",
        "def _add_trackers_to_magnet(magnet: str, trackers: list) -> str:\n",
        "    \"\"\"Append public trackers to magnet link for better peer discovery.\"\"\"\n",
        "    if not magnet.startswith('magnet:'):\n",
        "        return magnet\n",
        "    for tr in trackers:\n",
        "        magnet += '&tr=' + urllib.parse.quote(tr)\n",
        "    return magnet\n",
        "\n",
        "def _fmt_eta(remaining_bytes, rate):\n",
        "    \"\"\"Format estimated time of arrival.\"\"\"\n",
        "    if rate <= 0: \n",
        "        return 'ETA: ‚àû'\n",
        "    secs = int(remaining_bytes / rate)\n",
        "    m, s = divmod(secs, 60)\n",
        "    h, m = divmod(m, 60)\n",
        "    if h: \n",
        "        return f'ETA: {h}h {m}m'\n",
        "    if m: \n",
        "        return f'ETA: {m}m {s}s'\n",
        "    return f'ETA: {s}s'\n",
        "\n",
        "def _fmt_size(bytes_val):\n",
        "    \"\"\"Format bytes into human-readable size.\"\"\"\n",
        "    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:\n",
        "        if bytes_val < 1024.0:\n",
        "            return f\"{bytes_val:.2f} {unit}\"\n",
        "        bytes_val /= 1024.0\n",
        "    return f\"{bytes_val:.2f} PB\"\n",
        "\n",
        "def download_colab(magnet_link: str, save_path: str,\n",
        "                   max_peers: int = 400, \n",
        "                   peer_connect_timeout: int = 3,\n",
        "                   add_trackers: bool = True,\n",
        "                   stall_timeout: int = 900,\n",
        "                   auto_zip: bool = False, \n",
        "                   zip_name: str = None,\n",
        "                   resume_file: str = None):\n",
        "    \"\"\"Download a magnet to save_path using modern libtorrent 2.x patterns.\n",
        "    \n",
        "    Args:\n",
        "        magnet_link: Magnet URI to download\n",
        "        save_path: Directory to save downloaded files\n",
        "        max_peers: Maximum number of peer connections (default: 400)\n",
        "        peer_connect_timeout: Timeout for peer connections in seconds (default: 3)\n",
        "        add_trackers: Whether to inject public trackers (default: True)\n",
        "        stall_timeout: Seconds before considering download stalled (default: 900)\n",
        "        auto_zip: Whether to zip downloaded content (default: False)\n",
        "        zip_name: Custom name for zip file (default: uses torrent name)\n",
        "        resume_file: Path to save/load resume data for continuation (default: None)\n",
        "    \n",
        "    Returns:\n",
        "        bool: True if download completed successfully, False otherwise\n",
        "    \"\"\"\n",
        "    ses = None\n",
        "    h = None\n",
        "    \n",
        "    try:\n",
        "        # Optional public trackers (helps tracker-less magnets)\n",
        "        if add_trackers:\n",
        "            trackers = [\n",
        "                'udp://tracker.opentrackr.org:1337/announce',\n",
        "                'udp://tracker.torrent.eu.org:451/announce',\n",
        "                'udp://exodus.desync.com:6969/announce',\n",
        "                'udp://tracker.openbittorrent.com:6969/announce',\n",
        "                'udp://open.stealth.si:80/announce',\n",
        "                'udp://tracker.tiny-vps.com:6969/announce'\n",
        "            ]\n",
        "            magnet_link = _add_trackers_to_magnet(magnet_link, trackers)\n",
        "\n",
        "        # Configure session settings\n",
        "        settings = {\n",
        "            'user_agent': f'libtorrent/{getattr(lt, \"version\", \"unknown\")}',\n",
        "            'listen_interfaces': '0.0.0.0:6881',\n",
        "            'enable_dht': True,\n",
        "            'enable_lsd': True,\n",
        "            'announce_to_all_trackers': True,\n",
        "            'announce_to_all_tiers': True,\n",
        "            'connections_limit': max_peers,\n",
        "            'max_peerlist_size': max_peers * 2,\n",
        "            'peer_connect_timeout': peer_connect_timeout,\n",
        "            'request_timeout': 10,\n",
        "            'min_reconnect_time': 5,\n",
        "            'active_downloads': -1,\n",
        "            'active_seeds': -1,\n",
        "            'allow_multiple_connections_per_ip': True,\n",
        "        }\n",
        "        ses = _create_session(settings)\n",
        "\n",
        "        # Parse magnet and configure download\n",
        "        params = lt.parse_magnet_uri(magnet_link)\n",
        "        params.save_path = save_path\n",
        "        params.flags |= lt.torrent_flags.sequential_download\n",
        "        \n",
        "        # Load resume data if available\n",
        "        if resume_file and os.path.exists(resume_file):\n",
        "            try:\n",
        "                with open(resume_file, 'rb') as f:\n",
        "                    resume_data = f.read()\n",
        "                    if resume_data:\n",
        "                        params.resume_data = resume_data\n",
        "                        print('üì• Loaded resume data from', resume_file)\n",
        "            except Exception as e:\n",
        "                print(f'‚ö†Ô∏è Failed to load resume data: {e}')\n",
        "\n",
        "        h = ses.add_torrent(params)\n",
        "        print('üîó Magnet added')\n",
        "        print('üìç Save path:', save_path)\n",
        "\n",
        "        # Wait for metadata with timeout\n",
        "        meta_wait = 0\n",
        "        while not h.status().has_metadata:\n",
        "            print('üì° Fetching metadata...', end='\r')\n",
        "            time.sleep(1)\n",
        "            meta_wait += 1\n",
        "            if meta_wait > 120:\n",
        "                print('\n‚ö†Ô∏è Metadata fetch taking too long; continuing anyway')\n",
        "                break\n",
        "\n",
        "        s = h.status()\n",
        "        if s.has_metadata:\n",
        "            print(f'\n‚úÖ Metadata fetched ‚Äî Name: {s.name}')\n",
        "            print(f'üì¶ Size: {_fmt_size(s.total_wanted)}')\n",
        "        else:\n",
        "            print(f'\n‚ñ∂Ô∏è Starting without metadata')\n",
        "\n",
        "        # Progress loop with stall detection\n",
        "        last_progress = 0.0\n",
        "        last_change_ts = time.time()\n",
        "        \n",
        "        while not h.status().is_seeding:\n",
        "            s = h.status()\n",
        "            total = s.total_wanted if s.total_wanted > 0 else 0\n",
        "            done = s.total_wanted_done\n",
        "            remaining = max(0, total - done)\n",
        "            eta = _fmt_eta(remaining, s.download_rate) if total else 'ETA: ?'\n",
        "            \n",
        "            # Enhanced progress display\n",
        "            progress_bar = '‚ñà' * int(s.progress * 20) + '‚ñë' * (20 - int(s.progress * 20))\n",
        "            print(f\"\r{progress_bar} {s.progress*100:5.2f}% | \"\n",
        "                  f\"‚Üì{s.download_rate/1000:6.1f} kB/s | \"\n",
        "                  f\"‚Üë{s.upload_rate/1000:6.1f} kB/s | \"\n",
        "                  f\"peers {s.num_peers} | {eta}      ", end='')\n",
        "            \n",
        "            # Stall detection\n",
        "            if s.progress - last_progress > 0.001:\n",
        "                last_progress = s.progress\n",
        "                last_change_ts = time.time()\n",
        "            elif stall_timeout and stall_timeout > 0:\n",
        "                if (time.time() - last_change_ts > stall_timeout):\n",
        "                    print('\n‚è±Ô∏è Download appears stalled. Stopping.')\n",
        "                    break\n",
        "            \n",
        "            time.sleep(5)\n",
        "\n",
        "        completed = h.status().is_seeding\n",
        "        print()  # New line after progress\n",
        "        \n",
        "        if completed:\n",
        "            print('üéâ COMPLETE ‚Äî saved to', save_path)\n",
        "        else:\n",
        "            print('‚ö†Ô∏è Stopped before completion.')\n",
        "            # Save resume data for later continuation\n",
        "            if resume_file:\n",
        "                try:\n",
        "                    resume_data = h.save_resume_data()\n",
        "                    with open(resume_file, 'wb') as f:\n",
        "                        f.write(lt.bencode(resume_data))\n",
        "                    print(f'üíæ Resume data saved to {resume_file}')\n",
        "                    print('üí° Use the same resume_file to continue this download later')\n",
        "                except Exception as e:\n",
        "                    print(f'‚ö†Ô∏è Failed to save resume data: {e}')\n",
        "\n",
        "        # Optional zip with error handling\n",
        "        if auto_zip and completed:\n",
        "            try:\n",
        "                s = h.status()\n",
        "                name = s.name or 'torrent'\n",
        "                base = (zip_name or name).replace(' ', '_')\n",
        "                target_path = os.path.join(save_path, name)\n",
        "                \n",
        "                if os.path.isdir(target_path):\n",
        "                    root_dir = target_path\n",
        "                else:\n",
        "                    root_dir = save_path\n",
        "                \n",
        "                zip_target = os.path.join(save_path, base)\n",
        "                print(f'üóúÔ∏è Creating zip: {zip_target}.zip ...')\n",
        "                shutil.make_archive(zip_target, 'zip', root_dir)\n",
        "                \n",
        "                # Verify zip was created\n",
        "                zip_path = zip_target + '.zip'\n",
        "                if os.path.exists(zip_path):\n",
        "                    zip_size = os.path.getsize(zip_path)\n",
        "                    print(f'‚úÖ Zip created: {zip_path} ({_fmt_size(zip_size)})')\n",
        "                else:\n",
        "                    print('‚ö†Ô∏è Zip file not found after creation')\n",
        "            except Exception as e:\n",
        "                print(f'‚ùå Zip creation failed: {e}')\n",
        "                traceback.print_exc()\n",
        "        \n",
        "        return completed\n",
        "        \n",
        "    except KeyboardInterrupt:\n",
        "        print('\n‚ö†Ô∏è Interrupted by user')\n",
        "        # Save resume data on interrupt\n",
        "        if resume_file and h:\n",
        "            try:\n",
        "                resume_data = h.save_resume_data()\n",
        "                with open(resume_file, 'wb') as f:\n",
        "                    f.write(lt.bencode(resume_data))\n",
        "                print(f'üíæ Resume data saved to {resume_file}')\n",
        "                print('üí° Re-run with the same resume_file to continue')\n",
        "            except Exception as e:\n",
        "                print(f'‚ö†Ô∏è Failed to save resume data: {e}')\n",
        "        raise\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f'\n‚ùå Download failed: {e}')\n",
        "        traceback.print_exc()\n",
        "        return False\n",
        "        \n",
        "    finally:\n",
        "        # Proper cleanup to prevent memory leaks\n",
        "        if h:\n",
        "            try:\n",
        "                h.pause()\n",
        "                if ses:\n",
        "                    ses.remove_torrent(h)\n",
        "            except Exception as e:\n",
        "                print(f'‚ö†Ô∏è Cleanup warning: {e}')\n",
        "        if ses:\n",
        "            try:\n",
        "                del ses\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "print('‚úÖ Enhanced torrent engine loaded')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîé Pre‚ÄëFlight: Analyze Magnet\n",
        "\n",
        "Paste a magnet link to fetch metadata (name, size, files) before downloading. This does not download content ‚Äî it only retrieves metadata.\n",
        "\n",
        "**Tips**\n",
        "- Toggle public tracker injection if the magnet is tracker‚Äëpoor.\n",
        "- Adjust the timeout if metadata discovery is slow.\n",
        "- Click ‚ÄúSet as magnet‚Äù to populate the `magnet` variable used by examples below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Pre-flight magnet analyzer UI\n",
        "import sys, time, html\n",
        "from IPython.display import display, HTML, clear_output\n",
        "\n",
        "try:\n",
        "    import ipywidgets as widgets\n",
        "except Exception:\n",
        "    import subprocess, sys, importlib\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'ipywidgets'])\n",
        "    importlib.invalidate_caches()\n",
        "    import ipywidgets as widgets\n",
        "\n",
        "try:\n",
        "    import libtorrent as lt\n",
        "except Exception:\n",
        "    lt = None\n",
        "\n",
        "from typing import Dict, Any\n",
        "\n",
        "def _fmt_size(n):\n",
        "    for unit in ['B','KB','MB','GB','TB','PB']:\n",
        "        if n < 1024 or unit == 'PB':\n",
        "            return f\"{n:.2f} {unit}\"\n",
        "        n /= 1024\n",
        "\n",
        "def _safe(s):\n",
        "    return html.escape(str(s or ''))\n",
        "\n",
        "def analyze_magnet_metadata(magnet: str, *, timeout: int = 60, add_trackers: bool = True) -> Dict[str, Any]:\n",
        "    assert magnet.startswith('magnet:'), 'Not a magnet URI'\n",
        "    assert lt is not None, 'libtorrent not available ‚Äî run the setup cell above first.'\n",
        "    trackers = [\n",
        "        'udp://tracker.opentrackr.org:1337/announce',\n",
        "        'udp://tracker.torrent.eu.org:451/announce',\n",
        "        'udp://exodus.desync.com:6969/announce',\n",
        "        'udp://tracker.openbittorrent.com:6969/announce',\n",
        "        'udp://open.stealth.si:80/announce',\n",
        "        'udp://tracker.tiny-vps.com:6969/announce',\n",
        "    ]\n",
        "    if add_trackers and magnet.startswith('magnet:'):\n",
        "        import urllib.parse\n",
        "        for tr in trackers:\n",
        "            magnet += '&tr=' + urllib.parse.quote(tr)\n",
        "\n",
        "    def _mk_session():\n",
        "        try:\n",
        "            return lt.session({\n",
        "                'enable_dht': True,\n",
        "                'enable_lsd': True,\n",
        "                'announce_to_all_trackers': True,\n",
        "                'announce_to_all_tiers': True,\n",
        "                'connections_limit': 200,\n",
        "                'request_timeout': 10,\n",
        "            })\n",
        "        except TypeError:\n",
        "            sp = lt.settings_pack()\n",
        "            sp.set_bool(lt.settings_pack.enable_dht, True)\n",
        "            sp.set_bool(lt.settings_pack.enable_lsd, True)\n",
        "            sp.set_bool(lt.settings_pack.announce_to_all_trackers, True)\n",
        "            sp.set_bool(lt.settings_pack.announce_to_all_tiers, True)\n",
        "            sp.set_int(lt.settings_pack.connections_limit, 200)\n",
        "            sp.set_int(lt.settings_pack.request_timeout, 10)\n",
        "            ses = lt.session()\n",
        "            ses.apply_settings(sp)\n",
        "            return ses\n",
        "\n",
        "    ses = None\n",
        "    h = None\n",
        "    try:\n",
        "        ses = _mk_session()\n",
        "        p = lt.parse_magnet_uri(magnet)\n",
        "        p.save_path = '/tmp'\n",
        "        p.flags |= getattr(lt.torrent_flags, 'upload_mode', 0)\n",
        "        p.flags |= getattr(lt.torrent_flags, 'sequential_download', 0)\n",
        "        h = ses.add_torrent(p)\n",
        "\n",
        "        t0 = time.time()\n",
        "        while not h.status().has_metadata and (time.time() - t0) < timeout:\n",
        "            time.sleep(0.5)\n",
        "\n",
        "        s = h.status()\n",
        "        ih = ''\n",
        "        try:\n",
        "            ih = str(getattr(s, 'info_hash', ''))\n",
        "            if hasattr(s, 'info_hashes') and not ih:\n",
        "                ih = str(getattr(s.info_hashes, 'v2', getattr(s.info_hashes, 'v1', '')))\n",
        "        except Exception:\n",
        "            pass\n",
        "        info = {\n",
        "            'got_metadata': bool(s.has_metadata),\n",
        "            'name': s.name or '',\n",
        "            'info_hash': ih,\n",
        "            'trackers': [str(u.url) for u in (h.trackers() or [])] if hasattr(h, 'trackers') else [],\n",
        "            'num_peers': s.num_peers,\n",
        "            'files': [],\n",
        "            'total_size': None,\n",
        "            'piece_length': None,\n",
        "            'num_pieces': None,\n",
        "        }\n",
        "        if s.has_metadata:\n",
        "            ti = h.torrent_file()\n",
        "            total = getattr(ti, 'total_size', lambda: None)\n",
        "            total = total() if callable(total) else total\n",
        "            info['total_size'] = total or getattr(s, 'total_wanted', 0)\n",
        "            pl = getattr(ti, 'piece_length', lambda: None)\n",
        "            pl = pl() if callable(pl) else pl\n",
        "            np = getattr(ti, 'num_pieces', lambda: None)\n",
        "            np = np() if callable(np) else np\n",
        "            info['piece_length'] = pl\n",
        "            info['num_pieces'] = np\n",
        "            fs = getattr(ti, 'files', lambda: None)\n",
        "            fs = fs() if callable(fs) else fs\n",
        "            try:\n",
        "                num_files = fs.num_files()\n",
        "                files = []\n",
        "                for i in range(num_files):\n",
        "                    try:\n",
        "                        path = fs.file_path(i)\n",
        "                    except Exception:\n",
        "                        path = fs.file_name(i)\n",
        "                    size = fs.file_size(i)\n",
        "                    files.append((str(path), int(size)))\n",
        "                info['files'] = files\n",
        "                if info['name'] == '':\n",
        "                    name_fn = getattr(ti, 'name', lambda: '')\n",
        "                    info['name'] = name_fn() if callable(name_fn) else name_fn\n",
        "            except Exception:\n",
        "                pass\n",
        "        return info\n",
        "    finally:\n",
        "        try:\n",
        "            if h: h.pause()\n",
        "        except Exception:\n",
        "            pass\n",
        "        try:\n",
        "            if ses and h: ses.remove_torrent(h)\n",
        "        except Exception:\n",
        "            pass\n",
        "        try:\n",
        "            if ses: del ses\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "def render_report(meta: Dict[str, Any]):\n",
        "    if not meta.get('got_metadata'):\n",
        "        display(HTML(\"\"\"\n",
        "        <div style='border:1px solid #e2e8f0;border-radius:10px;padding:16px;background:#fffdf5'>\n",
        "          <div style='font-weight:600;font-size:16px'>Metadata not fetched within timeout.</div>\n",
        "          <div style='color:#555;margin-top:6px'>Try enabling public trackers and increasing the timeout.</div>\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "        return\n",
        "    name = _safe(meta.get('name') or 'Untitled')\n",
        "    total = meta.get('total_size') or 0\n",
        "    files = meta.get('files') or []\n",
        "    files_count = len(files)\n",
        "    largest = sorted(files, key=lambda x: x[1], reverse=True)[:10]\n",
        "    trackers = meta.get('trackers') or []\n",
        "    piece_len = meta.get('piece_length')\n",
        "    num_pieces = meta.get('num_pieces')\n",
        "    info_hash = _safe(meta.get('info_hash'))\n",
        "\n",
        "    rows = ''.join(\n",
        "        f\"<tr><td style='padding:6px 8px;border-bottom:1px solid #edf2f7'>{_safe(p)}</td><td style='padding:6px 8px;text-align:right;border-bottom:1px solid #edf2f7'>{_fmt_size(sz)}</td></tr>\"\n",
        "        for p, sz in largest\n",
        "    )\n",
        "    tracker_list = ''.join(f\"<li style='padding:2px 0'>{_safe(t)}</li>\" for t in trackers)\n",
        "\n",
        "    display(HTML(f\"\"\"\n",
        "    <div style='border:1px solid #e2e8f0;border-radius:12px;overflow:hidden'>\n",
        "      <div style='background:#1f2937;color:#fff;padding:14px 16px'>\n",
        "        <div style='font-size:15px;opacity:.85'>Torrent</div>\n",
        "        <div style='font-size:20px;font-weight:600'>{name}</div>\n",
        "      </div>\n",
        "      <div style='padding:14px 16px;background:#ffffff'>\n",
        "        <div style='display:flex;gap:16px;flex-wrap:wrap'>\n",
        "          <div style='background:#f1f5f9;border-radius:8px;padding:10px 12px;min-width:180px'>\n",
        "            <div style='font-size:12px;color:#475569'>Total Size</div>\n",
        "            <div style='font-size:16px;font-weight:600'>{_fmt_size(total)}</div>\n",
        "          </div>\n",
        "          <div style='background:#f1f5f9;border-radius:8px;padding:10px 12px;min-width:180px'>\n",
        "            <div style='font-size:12px;color:#475569'>Files</div>\n",
        "            <div style='font-size:16px;font-weight:600'>{files_count}</div>\n",
        "          </div>\n",
        "          <div style='background:#f1f5f9;border-radius:8px;padding:10px 12px;min-width:200px'>\n",
        "            <div style='font-size:12px;color:#475569'>Pieces</div>\n",
        "            <div style='font-size:16px;font-weight:600'>{(num_pieces or '?')} √ó {(_fmt_size(piece_len) if piece_len else '?')}</div>\n",
        "          </div>\n",
        "          <div style='background:#f1f5f9;border-radius:8px;padding:10px 12px;min-width:220px'>\n",
        "            <div style='font-size:12px;color:#475569'>Info Hash</div>\n",
        "            <div style='font-size:13px;font-weight:600;word-break:break-all'>{info_hash}</div>\n",
        "          </div>\n",
        "        </div>\n",
        "        <div style='margin-top:16px'>\n",
        "          <div style='font-weight:600;margin-bottom:6px'>Largest Files</div>\n",
        "          <table style='width:100%;border-collapse:collapse;font-size:13px'>\n",
        "            <thead>\n",
        "              <tr>\n",
        "                <th style='text-align:left;border-bottom:2px solid #e2e8f0;padding:6px 8px'>Path</th>\n",
        "                <th style='text-align:right;border-bottom:2px solid #e2e8f0;padding:6px 8px'>Size</th>\n",
        "              </tr>\n",
        "            </thead>\n",
        "            <tbody>\n",
        "              {rows if rows else \"<tr><td colspan=2 style=\\\"padding:8px;color:#64748b\\\">Single-file torrent or no file list available</td></tr>\"}\n",
        "            </tbody>\n",
        "          </table>\n",
        "          {\"<details style='margin-top:10px'><summary style='cursor:pointer'>Show all files</summary>\" + \"<ul style=\\\"margin:8px 0 0 16px\\\">\" + ''.join(f\"<li style='margin:2px 0'>{_safe(p)} ‚Äî <span style=\\\"color:#475569\\\">{_fmt_size(sz)}</span></li>\" for p, sz in files) + \"</ul></details>\" if files_count>10 else ''}\n",
        "        </div>\n",
        "        <div style='margin-top:16px'>\n",
        "          <details>\n",
        "            <summary style='font-weight:600;cursor:pointer'>Trackers ({len(trackers)})</summary>\n",
        "            <ul style='margin:8px 0 0 16px'>{tracker_list}</ul>\n",
        "          </details>\n",
        "        </div>\n",
        "      </div>\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "\n",
        "# Widgets\n",
        "magnet_input = widgets.Text(\n",
        "    placeholder='magnet:?xt=urn:btih:...',\n",
        "    description='Magnet:',\n",
        "    layout=widgets.Layout(width='80%')\n",
        ")\n",
        "add_trackers_chk = widgets.Checkbox(value=True, description='Add public trackers')\n",
        "timeout_slider = widgets.IntSlider(value=60, min=30, max=240, step=15, description='Timeout (s)', continuous_update=False)\n",
        "analyze_btn = widgets.Button(description='Analyze', button_style='primary', icon='search')\n",
        "set_btn = widgets.Button(description='Set as magnet', icon='check', tooltip=\"Set global variable 'magnet'\")\n",
        "\n",
        "out = widgets.Output()\n",
        "\n",
        "def on_analyze(_):\n",
        "    with out:\n",
        "        out.clear_output()\n",
        "        if not magnet_input.value.strip().startswith('magnet:'):\n",
        "            display(HTML('<div style=\\\'color:#b91c1c\\\'>Please enter a valid magnet URI.</div>'))\n",
        "            return\n",
        "        display(HTML('<div style=\\\'color:#475569\\\'>Fetching metadata‚Ä¶</div>'))\n",
        "        try:\n",
        "            meta = analyze_magnet_metadata(\n",
        "                magnet_input.value.strip(),\n",
        "                timeout=int(timeout_slider.value),\n",
        "                add_trackers=bool(add_trackers_chk.value),\n",
        "            )\n",
        "            out.clear_output()\n",
        "            render_report(meta)\n",
        "        except Exception as e:\n",
        "            out.clear_output()\n",
        "            display(HTML(f\"<div style='color:#b91c1c'>Error: {_safe(e)}</div>\"))\n",
        "\n",
        "def on_set(_):\n",
        "    globals()['magnet'] = magnet_input.value.strip()\n",
        "    with out:\n",
        "        display(HTML('<div style=\\\'color:#065f46\\\'>Set global variable <b>magnet</b>. The examples below will use it.</div>'))\n",
        "\n",
        "analyze_btn.on_click(on_analyze)\n",
        "set_btn.on_click(on_set)\n",
        "\n",
        "controls = widgets.VBox([\n",
        "    magnet_input,\n",
        "    widgets.HBox([add_trackers_chk, timeout_slider]),\n",
        "    widgets.HBox([analyze_btn, set_btn]),\n",
        "    out\n",
        "])\n",
        "display(controls)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Usage Examples\n",
        "\n",
        "Run the cells below to download torrents. Customize the parameters as needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example 1: Basic download\n",
        "# Replace with your magnet link\n",
        "magnet = 'magnet:?xt=urn:btih:YOUR_HASH_HERE'\n",
        "\n",
        "# Set save path (use Google Drive if mounted, otherwise local)\n",
        "if drive_mounted:\n",
        "    save_to = '/content/drive/MyDrive/Torrent'\n",
        "else:\n",
        "    save_to = '/content/torrents'\n",
        "\n",
        "# Download\n",
        "success = download_colab(\n",
        "    magnet_link=magnet,\n",
        "    save_path=save_to,\n",
        "    add_trackers=True,\n",
        "    stall_timeout=900  # 15 minutes\n",
        ")\n",
        "\n",
        "if success:\n",
        "    print('‚úÖ Download successful!')\n",
        "else:\n",
        "    print('‚ùå Download failed or incomplete')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example 2: Download with resume capability\n",
        "magnet = 'magnet:?xt=urn:btih:YOUR_HASH_HERE'\n",
        "\n",
        "if drive_mounted:\n",
        "    save_to = '/content/drive/MyDrive/Torrent'\n",
        "    resume_data_file = '/content/drive/MyDrive/Torrent/.resume_data'\n",
        "else:\n",
        "    save_to = '/content/torrents'\n",
        "    resume_data_file = '/content/torrents/.resume_data'\n",
        "\n",
        "# This will save resume data if interrupted\n",
        "# Run again with same resume_file to continue\n",
        "success = download_colab(\n",
        "    magnet_link=magnet,\n",
        "    save_path=save_to,\n",
        "    resume_file=resume_data_file,\n",
        "    add_trackers=True\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example 3: Download with auto-zip\n",
        "magnet = 'magnet:?xt=urn:btih:YOUR_HASH_HERE'\n",
        "\n",
        "if drive_mounted:\n",
        "    save_to = '/content/drive/MyDrive/Torrent'\n",
        "else:\n",
        "    save_to = '/content/torrents'\n",
        "\n",
        "success = download_colab(\n",
        "    magnet_link=magnet,\n",
        "    save_path=save_to,\n",
        "    auto_zip=True,\n",
        "    zip_name='my_download',\n",
        "    add_trackers=True\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example 4: Advanced configuration\n",
        "magnet = 'magnet:?xt=urn:btih:YOUR_HASH_HERE'\n",
        "\n",
        "if drive_mounted:\n",
        "    save_to = '/content/drive/MyDrive/Torrent'\n",
        "else:\n",
        "    save_to = '/content/torrents'\n",
        "\n",
        "success = download_colab(\n",
        "    magnet_link=magnet,\n",
        "    save_path=save_to,\n",
        "    max_peers=600,              # More connections\n",
        "    peer_connect_timeout=5,     # Longer timeout\n",
        "    stall_timeout=1800,         # 30 min stall timeout\n",
        "    add_trackers=True,\n",
        "    auto_zip=False\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Drive API Uploads (Resumable + Reliable)\n",
        "This section adds high-reliability uploads to Google Drive using the official API with resumable chunks, retries, and MD5 verification.\n",
        "\n",
        "- Prefer API uploads over direct Drive mount for large transfers.\n",
        "- Chunk size defaults to 10 MB with exponential backoff for 403/429/5xx.\n",
        "- Verifies integrity by comparing local MD5 with Drive's `md5Checksum`.\n",
        "- Create or reuse a Drive folder (default: `Torrent`).\n",
        "\n",
        "‚ö†Ô∏è Respect Google Colab/Drive ToS. Do not use P2P for unauthorized content."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Idempotent setup and environment summary\n",
        "import os, sys, platform, time\n",
        "\n",
        "API_UPLOAD_DEFAULT_FOLDER = 'Torrent'\n",
        "DEFAULT_LOCAL_DIR = '/content/torrents'\n",
        "os.makedirs(DEFAULT_LOCAL_DIR, exist_ok=True)\n",
        "\n",
        "try:\n",
        "    import psutil  # used later by monitor cell\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "def _env_summary():\n",
        "    py = sys.version.split()[0]\n",
        "    print(f'Python: {py} | Platform: {platform.system()} {platform.release()}')\n",
        "    if 'psutil' in sys.modules:\n",
        "        import psutil\n",
        "        vm = psutil.virtual_memory()\n",
        "        print(f'RAM: {vm.total/1e9:.1f} GB total, {vm.available/1e9:.1f} GB free')\n",
        "    print('IN_COLAB:', IN_COLAB)\n",
        "    print('Drive mounted:', drive_mounted)\n",
        "    print('Local working dir:', DEFAULT_LOCAL_DIR)\n",
        "\n",
        "_env_summary()\n",
        "print('‚úÖ Env summary ready ‚Äî API uploads will be used by default.')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install Drive API deps and prepare authentication utilities\n",
        "import importlib, subprocess, sys\n",
        "\n",
        "def _ensure(pkg):\n",
        "    try:\n",
        "        return importlib.import_module(pkg)\n",
        "    except Exception:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pkg])\n",
        "            importlib.invalidate_caches()\n",
        "            return importlib.import_module(pkg.split('==')[0])\n",
        "        except Exception as e:\n",
        "            print('Install failed:', pkg, e)\n",
        "            raise\n",
        "\n",
        "# Core deps\n",
        "_ensure('google-api-python-client')\n",
        "_ensure('google-auth-httplib2')\n",
        "_ensure('google-auth-oauthlib')\n",
        "_ensure('tenacity')\n",
        "_ensure('tqdm')\n",
        "_ensure('psutil')\n",
        "\n",
        "from tenacity import retry, wait_exponential, stop_after_attempt\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "import google.auth\n",
        "\n",
        "def get_drive_service():\n",
        "    \"\"\"Return an authenticated Drive v3 service.\n",
        "    In Colab: uses built-in auth flow. Outside: uses application default creds (e.g., service account).\n",
        "    \"\"\"\n",
        "    creds = None\n",
        "    if IN_COLAB:\n",
        "        try:\n",
        "            from google.colab import auth as colab_auth\n",
        "            colab_auth.authenticate_user()\n",
        "            creds, _ = google.auth.default()\n",
        "        except Exception as e:\n",
        "            print('Colab auth failed:', e)\n",
        "    if creds is None:\n",
        "        try:\n",
        "            creds, _ = google.auth.default()\n",
        "        except Exception as e:\n",
        "            print('ADC not found. For local: set GOOGLE_APPLICATION_CREDENTIALS to a service account JSON.')\n",
        "            raise e\n",
        "    return build('drive', 'v3', credentials=creds, cache_discovery=False)\n",
        "\n",
        "print('‚úÖ Drive API deps/auth utilities ready')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Resumable uploader with retries and MD5 verification\n",
        "import os, hashlib, time\n",
        "from typing import Optional, Dict\n",
        "from googleapiclient.errors import HttpError\n",
        "from tqdm import tqdm\n",
        "\n",
        "def _escape_q(s: str) -> str:\n",
        "    return s.replace("'", "\\'")\n",
        "\n",
        "def md5_file(path: str, buf_size: int = 4*1024*1024) -> str:\n",
        "    h = hashlib.md5()\n",
        "    with open(path, 'rb') as f:\n",
        "        while True:\n",
        "            b = f.read(buf_size)\n",
        "            if not b:\n",
        "                break\n",
        "            h.update(b)\n",
        "    return h.hexdigest()\n",
        "\n",
        "@retry(wait=wait_exponential(multiplier=1, min=1, max=60), stop=stop_after_attempt(7))\n",
        "def _drive_execute(req):\n",
        "    return req.execute()\n",
        "\n",
        "def ensure_folder(service, name: str, parent_id: Optional[str] = None) -> str:\n",
        "    q = f\"mimeType='application/vnd.google-apps.folder' and name='{_escape_q(name)}' and trashed=false\"\n",
        "    if parent_id:\n",
        "        q += f\" and '{parent_id}' in parents\"\n",
        "    res = _drive_execute(service.files().list(q=q, fields='files(id, name)', pageSize=1))\n",
        "    files = res.get('files', [])\n",
        "    if files:\n",
        "        return files[0]['id']\n",
        "    body = {'name': name, 'mimeType': 'application/vnd.google-apps.folder'}\n",
        "    if parent_id:\n",
        "        body['parents'] = [parent_id]\n",
        "    created = _drive_execute(service.files().create(body=body, fields='id, name'))\n",
        "    return created['id']\n",
        "\n",
        "def find_by_md5(service, md5: str) -> Optional[Dict]:\n",
        "    q = f\"md5Checksum='{_escape_q(md5)}' and trashed=false\"\n",
        "    res = _drive_execute(service.files().list(q=q, fields='files(id, name, size, md5Checksum)', pageSize=1))\n",
        "    files = res.get('files', [])\n",
        "    return files[0] if files else None\n",
        "\n",
        "def upload_resumable(service, file_path: str, drive_folder_id: Optional[str] = None, chunk_mb: int = 10) -> Dict:\n",
        "    assert os.path.isfile(file_path), f'File not found: {file_path}'\n",
        "    fname = os.path.basename(file_path)\n",
        "    size = os.path.getsize(file_path)\n",
        "    local_md5 = md5_file(file_path)\n",
        "    existing = find_by_md5(service, local_md5)\n",
        "    if existing:\n",
        "        print(f'‚ôªÔ∏è Already on Drive: {existing["name"]} (id={existing["id"]}) ‚Äî MD5 match')\n",
        "        return existing\n",
        "\n",
        "    body = {'name': fname}\n",
        "    if drive_folder_id:\n",
        "        body['parents'] = [drive_folder_id]\n",
        "\n",
        "    media = MediaFileUpload(file_path, chunksize=chunk_mb*1024*1024, resumable=True)\n",
        "    request = service.files().create(body=body, media_body=media, fields='id, name, md5Checksum, size')\n",
        "\n",
        "    response = None\n",
        "    with tqdm(total=size, unit='B', unit_scale=True, desc=f'Upload {fname}') as pbar:\n",
        "        last = 0\n",
        "        while response is None:\n",
        "            try:\n",
        "                status, response = request.next_chunk()\n",
        "                if status:\n",
        "                    cur = int(status.resumable_progress or 0)\n",
        "                    pbar.update(cur - last)\n",
        "                    last = cur\n",
        "            except HttpError as e:\n",
        "                if e.resp.status in (403, 429, 500, 502, 503, 504):\n",
        "                    wait_s = min(60, 2 ** (min(6, int(pbar.n / max(1, chunk_mb*1024*1024)))))\n",
        "                    print(f'HTTP {e.resp.status} ‚Äî backing off {wait_s}s ...')\n",
        "                    time.sleep(wait_s)\n",
        "                else:\n",
        "                    raise\n",
        "\n",
        "    # Verify integrity\n",
        "    if response and response.get('md5Checksum'):\n",
        "        if response['md5Checksum'] != local_md5:\n",
        "            raise RuntimeError('MD5 mismatch after upload ‚Äî possible corruption')\n",
        "        else:\n",
        "            print('‚úÖ MD5 verified on Drive')\n",
        "    print(f"‚úÖ Upload complete: {response['name']} (id={response['id']})")\n",
        "    return response\n",
        "\n",
        "print('‚úÖ Resumable uploader loaded')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Lightweight resource monitor (optional)\n",
        "import threading, time\n",
        "try:\n",
        "    import psutil\n",
        "except Exception:\n",
        "    psutil = None\n",
        "\n",
        "def start_resource_monitor(interval: int = 5, duration: int = 0):\n",
        "    \"\"\"Print CPU/RAM/disk/net every `interval` seconds.\n",
        "    If duration>0, auto-stops after duration seconds. Returns a stop() function.\n",
        "    \"\"\"\n",
        "    if psutil is None:\n",
        "        print('psutil not available ‚Äî skipping monitor')\n",
        "        return lambda: None\n",
        "    stop_evt = threading.Event()\n",
        "    net0 = psutil.net_io_counters()\n",
        "    t0 = time.time()\n",
        "    def _loop():\n",
        "        while not stop_evt.is_set():\n",
        "            vm = psutil.virtual_memory()\n",
        "            cpu = psutil.cpu_percent(interval=None)\n",
        "            net = psutil.net_io_counters()\n",
        "            rx = (net.bytes_recv - net0.bytes_recv) / max(1e-9, (time.time()-t0))\n",
        "            tx = (net.bytes_sent - net0.bytes_sent) / max(1e-9, (time.time()-t0))\n",
        "            print(f'CPU {cpu:4.1f}% | RAM {vm.percent:4.1f}% | Net RX {rx/1e6:6.2f} MB/s TX {tx/1e6:6.2f} MB/s')\n",
        "            if duration and (time.time()-t0) >= duration:\n",
        "                break\n",
        "            stop_evt.wait(interval)\n",
        "    th = threading.Thread(target=_loop, daemon=True)\n",
        "    th.start()\n",
        "    return stop_evt.set\n",
        "\n",
        "print('‚úÖ Resource monitor ready (start_resource_monitor)')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 5: Download locally, then upload to Drive via API (recommended)\n",
        "This avoids Drive mount write stalls and uses resumable uploads with verification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Configure your magnet and target folder name on Drive\n",
        "magnet = 'magnet:?xt=urn:btih:YOUR_HASH_HERE'\n",
        "drive_folder_name = API_UPLOAD_DEFAULT_FOLDER  # or change\n",
        "\n",
        "local_dir = DEFAULT_LOCAL_DIR\n",
        "os.makedirs(local_dir, exist_ok=True)\n",
        "zip_label = 'transfer_package'  # predictable zip name for upload\n",
        "\n",
        "# Optional: start a short resource monitor during transfer\n",
        "stop_monitor = start_resource_monitor(interval=10, duration=0)\n",
        "\n",
        "# 1) Download locally and zip for fewer files\n",
        "ok = download_colab(\n",
        "    magnet_link=magnet,\n",
        "    save_path=local_dir,\n",
        "    auto_zip=True,\n",
        "    zip_name=zip_label,\n",
        "    add_trackers=True,\n",
        "    stall_timeout=900\n",
        ")\n",
        "\n",
        "# 2) Upload the produced zip via Drive API\n",
        "zip_path = os.path.join(local_dir, f'{zip_label}.zip')\n",
        "if ok and os.path.exists(zip_path):\n",
        "    service = get_drive_service()\n",
        "    folder_id = ensure_folder(service, drive_folder_name)\n",
        "    print('Uploading to Drive folder:', drive_folder_name, '(id=', folder_id, ')')\n",
        "        res = upload_resumable(service, zip_path, drive_folder_id=folder_id, chunk_mb=10)
\n",
        "    print('Drive file id:', res['id'])\n",
        "    print('Open:', f"https://drive.google.com/file/d/{res['id']}/view?usp=drivesdk")\n",
        "else:\n",
        "    print('Nothing to upload ‚Äî download may have failed or zip not found.')\n",
        "\n",
        "# 3) Stop monitor (if running)\n",
        "try: stop_monitor()\n",
        "except Exception: pass\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
